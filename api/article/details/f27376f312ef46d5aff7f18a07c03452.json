{
    "props": {
        "pageProps": {
            "query": {
                "id": "f27376f312ef46d5aff7f18a07c03452"
            },
            "ieBrowser": false,
            "needRefresh": false,
            "writingDetail": {
                "id": 82970,
                "outId": "f27376f312ef46d5aff7f18a07c03452",
                "articleOutId": "f27376f312ef46d5aff7f18a07c03452",
                "html": "<h3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px; margin-bottom: 15px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: block;\"><span class=\"prefix\" style=\"display: none;\"></span><span class=\"content\" style=\"font-size: 20px; color: rgb(0, 0, 0); line-height: 1.5em; letter-spacing: 0em; text-align: left; font-weight: bold; display: block;\">内容概述</span><span class=\"suffix\" style=\"display: none;\"></span></h3> \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">这一节和上一节最大的区别在于使用了函数来表示状态值和动作值。</p> \n<h3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px; margin-bottom: 15px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: block;\"><span class=\"prefix\" style=\"display: none;\"></span><span class=\"content\" style=\"font-size: 20px; color: rgb(0, 0, 0); line-height: 1.5em; letter-spacing: 0em; text-align: left; font-weight: bold; display: block;\">状态值估计的算法</span><span class=\"suffix\" style=\"display: none;\"></span></h3> \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">这一节的目的是估计一个给定策略的状态值，是做 policy evaluation 。<br> 目标函数：$$J(w)=\\mathbb{E}[(v_\\pi(S)-\\hat{v}(S,w))^2]$$ 我们的目标就是找到最优的 $w$ 去最小化目标函数 $J(w)$ 。</p> \n<ul data-tool=\"mdnice编辑器\" style=\"list-style-type: disc; margin-top: 8px; margin-bottom: 8px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 25px; padding-right: 0px; color: rgb(0, 0, 0);\"> \n <li> \n  <section style=\"margin-top: 5px; margin-bottom: 5px; color: rgb(1, 1, 1); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; font-weight: normal;\">\n    使用平均分布 \n  </section></li> \n</ul> $$J(w)=\\mathbb{E}[(v_\\pi(S)-\\hat{v}(S,w))^2]=\\frac{1}{|S|}\\sum_{s \\in S}(v_\\pi(s)-\\hat{v}(s,w))^2 $$ \n<ul data-tool=\"mdnice编辑器\" style=\"list-style-type: disc; margin-top: 8px; margin-bottom: 8px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 25px; padding-right: 0px; color: rgb(0, 0, 0);\"> \n <li> \n  <section style=\"margin-top: 5px; margin-bottom: 5px; color: rgb(1, 1, 1); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; font-weight: normal;\">\n    使用平稳分布 \n  </section></li> \n</ul> $$J(w)=\\mathbb{E}[(v_\\pi(S)-\\hat{v}(S,w))^2]=\\sum_{s \\in S}d_\\pi(s)(v_\\pi(s)-\\hat{v}(s,w))^2 $$ \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">关于平稳分布的关系式如下，其中 $P_\\pi$ 为状态转移矩阵。$$d_\\pi^T=d_\\pi^TP_\\pi$$ 为了最小化目标函数 $J(w)$ ，可以使用梯度下降算法：</p> $$\\begin{align} w_{t+1}=&amp;\\;w_t-a_t\\nabla_wJ(w_t) \\nonumber \\\\[0.5em] =&amp;\\;w_t+a_t(v_\\pi(s_t)-\\hat{v}(s_t,w_t)) \\nabla_w\\hat{v}(s_t,w_t) \\nonumber \\\\[0.5em] \\end{align} $$ \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">对于其中的 $v_\\pi(s_t)$ ，可以使用带函数逼近的 TD learning 来估计。</p> $$\\begin{align} w_{t+1}=&amp;\\;w_t+a_t(r_{t+1}+\\gamma \\hat{v}(s_{t+1},w_t)-\\hat{v}(s_t,w_t)) \\nabla_w\\hat{v}(s_t,w_t) \\nonumber \\\\[0.5em] \\end{align} $$ \n<h3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px; margin-bottom: 15px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: block;\"><span class=\"prefix\" style=\"display: none;\"></span><span class=\"content\" style=\"font-size: 20px; color: rgb(0, 0, 0); line-height: 1.5em; letter-spacing: 0em; text-align: left; font-weight: bold; display: block;\">带有值函数近似的 SARSA</span><span class=\"suffix\" style=\"display: none;\"></span></h3> \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">和估计状态值时一样，只不过把 $v$ 换成了 $q$ 。</p> $$\\begin{align} w_{t+1}=&amp;\\;w_t+a_t(r_{t+1}+\\gamma \\hat{q}(s_{t+1},a_{t+1},w_t)-\\hat{q}(s_t,a_t,w_t)) \\nabla_w\\hat{q}(s_t,a_t,w_t) \\nonumber \\\\[0.5em] \\end{align} $$ \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">流程如下，和上一章类似，不过这里更新权重而不是直接更新动作值。 <img src=\"https://files.mdnice.com/user/71967/e0f1a4c7-37de-4ea0-84eb-46f6957fa70d.png\" alt style=\"display: block; margin-top: 0px; margin-right: auto; margin-bottom: 0px; margin-left: auto; max-width: 100%;\"></p> \n<h3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px; margin-bottom: 15px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: block;\"><span class=\"prefix\" style=\"display: none;\"></span><span class=\"content\" style=\"font-size: 20px; color: rgb(0, 0, 0); line-height: 1.5em; letter-spacing: 0em; text-align: left; font-weight: bold; display: block;\">带有值函数近似的 Q-learning</span><span class=\"suffix\" style=\"display: none;\"></span></h3> \n<figure data-tool=\"mdnice编辑器\" style=\"margin-top: 10px; margin-bottom: 10px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: flex; flex-direction: column; justify-content: center; align-items: center;\"> \n <img src=\"https://files.mdnice.com/user/71967/e2147a1f-05a8-415f-bd4d-8d074445df01.png\" alt style=\"display: block; margin-top: 0px; margin-right: auto; margin-bottom: 0px; margin-left: auto; max-width: 100%; border-top-style: none; border-bottom-style: none; border-left-style: none; border-right-style: none; border-top-width: 3px; border-bottom-width: 3px; border-left-width: 3px; border-right-width: 3px; border-top-color: rgba(0, 0, 0, 0.4); border-bottom-color: rgba(0, 0, 0, 0.4); border-left-color: rgba(0, 0, 0, 0.4); border-right-color: rgba(0, 0, 0, 0.4); border-top-left-radius: 0px; border-top-right-radius: 0px; border-bottom-right-radius: 0px; border-bottom-left-radius: 0px; object-fit: fill; box-shadow: rgba(0, 0, 0, 0) 0px 0px 0px 0px;\"> \n</figure> \n<h3 data-tool=\"mdnice编辑器\" style=\"margin-top: 30px; margin-bottom: 15px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; display: block;\"><span class=\"prefix\" style=\"display: none;\"></span><span class=\"content\" style=\"font-size: 20px; color: rgb(0, 0, 0); line-height: 1.5em; letter-spacing: 0em; text-align: left; font-weight: bold; display: block;\">DQN</span><span class=\"suffix\" style=\"display: none;\"></span></h3> \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">目标函数如下，其中 $(S,A,R,S')$ 是随机变量。</p> $$J(w)=\\mathbb{E}[(R+\\gamma \\max_{a \\in A(S')} \\hat{q} (S',a,w)-\\hat{q}(S,A,w))^2] $$ \n<p data-tool=\"mdnice编辑器\" style=\"color: rgb(0, 0, 0); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; text-indent: 0em; margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; padding-top: 8px; padding-bottom: 8px; padding-left: 0px; padding-right: 0px;\">由于目标函数中两部分都有 $w$ ，比较难求梯度，所以使用了2个网络，将两个 $q$ 区分开来。</p> $$\\begin{align} J=&amp;\\;\\mathbb{E}[(R+\\gamma \\max_{a \\in A(S')} \\hat{q} (S',a,w_T)-\\hat{q}(S,A,w))^2] \\nonumber \\\\[0.5em] \\nabla_wJ=&amp;\\;\\mathbb{E}[(R+\\gamma \\max_{a \\in A(S')} \\hat{q} (S',a,w_T)-\\hat{q}(S,A,w))\\nabla_w\\hat{q}(S,A,w)] \\nonumber \\\\[0.5em] \\end{align} $$ \n<ul data-tool=\"mdnice编辑器\" style=\"list-style-type: disc; margin-top: 8px; margin-bottom: 8px; margin-left: 0px; margin-right: 0px; padding-top: 0px; padding-bottom: 0px; padding-left: 25px; padding-right: 0px; color: rgb(0, 0, 0);\"> \n <li> \n  <section style=\"margin-top: 5px; margin-bottom: 5px; color: rgb(1, 1, 1); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; font-weight: normal;\">\n    让 $w$ 和 $w_T$ 分别表示主网络和目标网络的参数，它们初始设置为相同。在每轮迭代的时候，从 replay buffer 中取出一批次样本 $(s,a,r,s')$ ，将 $w_T$ 固定不动，去更新 $w$ ，更新了一段时间来赋值给 $w_T$ \n  </section></li> \n <li> \n  <section style=\"margin-top: 5px; margin-bottom: 5px; color: rgb(1, 1, 1); font-size: 16px; line-height: 1.8em; letter-spacing: 0em; text-align: left; font-weight: normal;\">\n    Experience replay 。收集经验样本（experience/sample）的时候是有先后顺序的，在收集到一些经验样本后，在使用的时候，我们不会按顺序使用这些样本。相反，我们会将它们存储在一个名为重放缓冲区（replay buffer）。训练的时候，从中随机抽样。 \n  </section></li> \n</ul>",
                "title": "（八）值函数近似",
                "categoryId": 1,
                "categoryName": "后端",
                "tagId": 100,
                "tagName": "后端",
                "userId": 71967,
                "userOutId": "409884201692",
                "username": "lkll",
                "avatar": "",
                "description": "内容概述这一节和上一节最大的区别在于使用了函数来表示状态值和动作值。状态值估计的算法这一节的目的是估计一个给定策略的状态值，是做policyevaluation。目标函数：$$J(w)=\\mathbb",
                "level": 1,
                "publishTime": "2024/09/02",
                "readingNum": 9,
                "likeNum": 0,
                "introduction": null,
                "followWords": null,
                "followPic": null,
                "isFollowing": false,
                "isLike": false,
                "isSelf": false,
                "type": 1,
                "isVisible": true,
                "invisibleReason": null,
                "writingColumn": {
                    "columnOutId": "64d0f2cc864e4406abf62891540556ba",
                    "name": "强化学习",
                    "briefIntro": "与强化学习相关的基础知识",
                    "cover": "https://files.mdnice.com/common/community/default-column-cover.jpg",
                    "writingNum": 6,
                    "createTime": "2024-08-06 19:02"
                }
            }
        },
        "__N_SSP": true
    },
    "page": "/writing/[id]",
    "query": {
        "id": "f27376f312ef46d5aff7f18a07c03452"
    },
    "buildId": "ErZPkD4oq6iwH2nj6Dpcx",
    "isFallback": false,
    "gssp": true,
    "appGip": true
}